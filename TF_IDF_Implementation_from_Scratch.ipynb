{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " TF-IDF Implementation from Scratch",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOc/l6RZuuO8RzM0JXWv9Za",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gangabhavani145/PGD_Practice/blob/main/TF_IDF_Implementation_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_kcNB4RmiGQ"
      },
      "source": [
        "##TF-IDF Simple Implementation from Scratch\n",
        "###TF-IDF is a technique which is used to convert text to vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTk1tXZ6oJYG"
      },
      "source": [
        "#importing required libraries and functions\n",
        "\n",
        "import numpy as np\n",
        "from math import log"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9WWxtQlnLgF"
      },
      "source": [
        "###We will now see how to apply tf-idf to convert given corpus (collection of documents) containing text to Vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85KObCLjpXsv"
      },
      "source": [
        "corpus = [\n",
        "     'this is the first document mostly',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document here',\n",
        "]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nomsD2UEob3j"
      },
      "source": [
        "Step 1> Construct a list of unique words from corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5FtX4LTqTU2",
        "outputId": "e477dd0e-2383-4904-eda7-2d84734e99c8"
      },
      "source": [
        "corpus_words = []\n",
        "\n",
        "# iterating through each sentence/document(called in NLP), splitting sentences to words and using set() to get only unique words.\n",
        "for sent in corpus:\n",
        "  words = sent.split()\n",
        "  corpus_words.extend(words)\n",
        "print(\"words in corpus: \",corpus_words)\n",
        "  \n",
        "# we have 11 unique words in corpus\n",
        "unique_words = list(set(corpus_words))\n",
        "print(\"Unique words list: \", unique_words)\n",
        "print(len(unique_words))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "words in corpus:  ['this', 'is', 'the', 'first', 'document', 'mostly', 'this', 'document', 'is', 'the', 'second', 'document', 'and', 'this', 'is', 'the', 'third', 'one', 'is', 'this', 'the', 'first', 'document', 'here']\n",
            "Unique words list:  ['one', 'is', 'first', 'mostly', 'this', 'here', 'second', 'third', 'the', 'and', 'document']\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IErz_OEbqG4c"
      },
      "source": [
        "Step 2> Finding Frequency/count of each unique word in corpus and creating dictionary which stores word:word_frequency as key:value pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUnxwpz1v9v_",
        "outputId": "c14b5b47-34fd-4417-d815-eb45835c454a"
      },
      "source": [
        "word_freq_dict = {}\n",
        "\n",
        "for word in unique_words:\n",
        "  if word in corpus_words:\n",
        "    word_freq = corpus_words.count(word)\n",
        "  print(word, \" frequency is \",word_freq)\n",
        "\n",
        "  # adding key:value pairs to dictionary\n",
        "  word_freq_dict[word] = word_freq\n",
        "\n",
        "# sorting the unique words based on their frequency(value) in decreasing order \n",
        "sorted_unique_words = sorted(word_freq_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# sorted dictionary with word:word frequency as key:value pairs\n",
        "sorted_unique_words_dict  = dict(sorted_unique_words)\n",
        "print(\"sorted dictionary: \", sorted_unique_words_dict)\n",
        "\n",
        "# list of keys or unique words of dictionary\n",
        "unique_words_list = list(sorted_unique_words_dict.keys())\n",
        "print(\"sorted keys of dictionary: \", unique_words_list)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one  frequency is  1\n",
            "is  frequency is  4\n",
            "first  frequency is  2\n",
            "mostly  frequency is  1\n",
            "this  frequency is  4\n",
            "here  frequency is  1\n",
            "second  frequency is  1\n",
            "third  frequency is  1\n",
            "the  frequency is  4\n",
            "and  frequency is  1\n",
            "document  frequency is  4\n",
            "sorted dictionary:  {'is': 4, 'this': 4, 'the': 4, 'document': 4, 'first': 2, 'one': 1, 'mostly': 1, 'here': 1, 'second': 1, 'third': 1, 'and': 1}\n",
            "sorted keys of dictionary:  ['is', 'this', 'the', 'document', 'first', 'one', 'mostly', 'here', 'second', 'third', 'and']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0up2GIsNsHFq"
      },
      "source": [
        "Step 3> computing IDF for unique words\n",
        "\n",
        "Inverse Document-Frequency(IDF) for a word = Log ((Total number of Documents in Corpus)/(Number of documents in corpus containing that word))\n",
        "\n",
        "Observation:  \n",
        "*   For frequent words, IDF will be lower.\n",
        "*   For rare words, IDF will be higher and \n",
        "If word occurs in all documents then IDP will be Zero. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJUYUqx1fuvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a093ac0e-37fe-4f54-ed4b-996d18329d98"
      },
      "source": [
        "idf = {}\n",
        "len_corpus = len(corpus)\n",
        "\n",
        "for word in unique_words_list:\n",
        "  count = 0\n",
        "  for sentence in corpus:\n",
        "    sentence = sentence.split()\n",
        "    if word in sentence:\n",
        "      count += 1\n",
        "  idf[word] = log(len_corpus/count)\n",
        "\n",
        "idf_of_word  = idf[word]\n",
        "print(\"IDF for unique words: \",idf)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IDF for unique words:  {'is': 0.0, 'this': 0.0, 'the': 0.0, 'document': 0.28768207245178085, 'first': 0.6931471805599453, 'one': 1.3862943611198906, 'mostly': 1.3862943611198906, 'here': 1.3862943611198906, 'second': 1.3862943611198906, 'third': 1.3862943611198906, 'and': 1.3862943611198906}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGUwn4Y_ugBU"
      },
      "source": [
        "Step 4> Computing TF for each word in corpus.\n",
        "Term Frequency(TF) for a word = (Number of times word occurs in a document) / (Total number of words in that document)\n",
        "\n",
        "TF tells the probability of word occuring in the document.\n",
        "\n",
        "TF always lies in the range of [0,1]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "TF-IDF for each word = TF of word  * IDF of word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrlyeD6U7anr",
        "outputId": "d2a883d4-c5bd-48c5-e19f-bf99700bca5a"
      },
      "source": [
        "tf_idf= []\n",
        "for sentence in corpus:\n",
        "  sentence = sentence.split()\n",
        "  for word in sentence:\n",
        "    # Term frequency of each word in corpus \n",
        "    tf_of_word = sentence.count(word)/len(sentence)\n",
        "\n",
        "    # Computing TF-IDF for each word in corpus \n",
        "    tf_idf_of_word = tf_of_word * idf[word]\n",
        "\n",
        "    # rounding values to 2 decimals\n",
        "    tf_idf_of_word = round((tf_idf_of_word), 2)\n",
        "    tf_idf.append(tf_idf_of_word)\n",
        "\n",
        "\n",
        "tf_idf_arr = np.array(tf_idf)\n",
        "tf_idf_arr = np.reshape(tf_idf_arr, (4,6))\n",
        "print(tf_idf_arr)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.   0.   0.   0.12 0.05 0.23]\n",
            " [0.   0.1  0.   0.   0.23 0.1 ]\n",
            " [0.23 0.   0.   0.   0.23 0.23]\n",
            " [0.   0.   0.   0.12 0.05 0.23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vFwFY8S-Mxk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}